---
caption: #what displays in the portfolio grid:
  title: UnrealFall
  subtitle: Synthetic Action Video Generation
  thumbnail: assets/img/portfolio/UnrealFall.png
  
#what displays when the item is clicked:
title: UnrealFall
subtitle: Synthetic Video Data Generation Framework
image: assets/img/portfolio/UnrealFallAbstract.png #main image, can be a link or a file in assets/img/portfolio
alt: UnrealFall

---
Humans perform a variety of actions, some of which are infrequent but crucial for data collection. Synthetic generation techniques are highly effective in these situations, enhancing the data for such rare actions. In response to this need, we present UnrealFall, a robust framework developed within Unreal Engine 5, designed for the generation of human action video data in hyper-realistic virtual scenes. It addresses the scarcity and limited diversity in existing datasets for actions like falls by leveraging synthetic motion generation through text-guided generative models, Gaussian Splatting technology, and MetaHumans. The usefulness of the framework is demonstrated by its capability to produce a synthetic video dataset featuring elderly individuals falling in various settings. The value of the dataset is demonstrated by its successful use in training a VideoMAE model, in conjunction with the UCF101 and various fall-specific datasets. This versatility in generating data across a spectrum of actions and environments positions our framework as a valuable tool for broader applications such as digital twin creation and dataset augmentation. The code and data are available for research at project website, 
[darkviid.github.io/UnrealFall/](https://darkviid.github.io/UnrealFall/).

