---
caption: #what displays in the portfolio grid:
  title: MixerMDM
  subtitle: Mixing Motion Distributions for Diverse Human Motion Generation
  thumbnail: assets/img/portfolio/MixerMDM.jpg
  
#what displays when the item is clicked:
title: MixerMDM
subtitle: Mixing Motion Distributions for Diverse Human Motion Generation
image: assets/img/portfolio/MixerMDM.jpg #main image, can be a link or a file in assets/img/portfolio
alt: MixerMDM

---
Generating diverse and realistic human motions from textual descriptions remains a core challenge in human motion generation. Existing models often suffer from limited diversity due to the reliance on a single motion distribution during sampling. To address this, we propose [MixerMDM](https://pabloruizponce.com/papers/MixerMDM), a novel approach that enhances motion diversity by mixing distributions at sampling time. Our method introduces a flexible framework that combines multiple motion priors, allowing for a richer exploration of the motion space while preserving fidelity to the input text. We evaluate MixerMDM on the HumanML3D and KIT-ML datasets, showing significant improvements in both diversity and quality of the generated motions. This method opens up new avenues for controllable and expressive motion generation, with potential applications in animation, virtual agents, and embodied AI.

<iframe src="https://pabloruizponce.com/papers/MixerMDM" width="100%" height="600px"></iframe>
